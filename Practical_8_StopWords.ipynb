{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43262a0f-8ab5-4c3c-935d-15527cabde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop WordsÂ¶\n",
    "#Theory: Stop words are words that are commonly used in natural language but are usually removed from text data before processing, as they do not carry much meaning and may interfere with natural language processing algorithms. Examples of stop words include \"a\", \"an\", \"the\", \"in\", \"is\", \"on\", \"and\", \"of\", and \"to\". Removing stop words can reduce the size of text data, improve text processing speed, and potentially improve the accuracy of natural language processing tasks such as text classification or sentiment analysis. However, it is important to note that removing stop words is not always necessary or beneficial for all natural language processing tasks, and it can depend on the specific application and type of text data being analyzed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e82a60-7a09-4e0f-b01a-d0f9ead4e4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ompan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ompan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeb291bd-bfcb-491e-bfa1-1f507ad5123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1806c4-9c98-40ca-9f24-b71fb7e401ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_tokenize is a function in Python that splits a given sentence into words using the NLTK library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663befaa-4517-42eb-bee2-8194d50141cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "TOKENS\n",
      "---------------\n",
      "['Cristiano', 'Ronaldo', 'was', 'born', 'on', 'February', '5', ',', '1985', ',', 'in', 'Funchal', ',', 'Madeira', ',', 'Portugal']\n",
      "---------------\n",
      "STOPWORDS\n",
      "---------------\n",
      "['Cristiano', 'Ronaldo', 'born', 'February', '5', ',', '1985', ',', 'Funchal', ',', 'Madeira', ',', 'Portugal']\n"
     ]
    }
   ],
   "source": [
    "a = set(stopwords.words('english'))\n",
    "text = \"Cristiano Ronaldo was born on February 5, 1985, in Funchal, Madeira, Portugal\"\n",
    "text1 = word_tokenize(text)\n",
    "print('-'*15)\n",
    "print(\"TOKENS\")\n",
    "print('-'*15)\n",
    "print(text1)\n",
    "stopwords = [x for x in text1 if x not in a]\n",
    "print('-'*15)\n",
    "print(\"STOPWORDS\")\n",
    "print('-'*15)\n",
    "print(stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb875ac5-96c5-4eed-ac19-b9c94346eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS tagging is a technique used in Natural Language Processing. It categorizes the tokens in a text as nouns, verbs, adjectives, and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f1fdfa5-3db4-486f-a326-7ab08da7d008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "POS TAG\n",
      "---------------\n",
      "[('vote', 'NN')]\n",
      "[('to', 'TO')]\n",
      "[('choose', 'NN')]\n",
      "[('a', 'DT')]\n",
      "[('particular', 'JJ')]\n",
      "[('man', 'NN')]\n",
      "[('or', 'CC')]\n",
      "[('a', 'DT')]\n",
      "[('group', 'NN')]\n",
      "[('(', '(')]\n",
      "[('party', 'NN')]\n",
      "[(')', ')')]\n",
      "[('to', 'TO')]\n",
      "[('represent', 'NN')]\n",
      "[('them', 'PRP')]\n",
      "[('in', 'IN')]\n",
      "[('parliament', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"vote to choose a particular man or a group (party) to represent them in parliament\"\n",
    "tex = word_tokenize(text)\n",
    "print('-'*15)\n",
    "print(\"POS TAG\")\n",
    "print('-'*15)\n",
    "for token in tex:\n",
    "    print(nltk.pos_tag([token]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6f417-ebea-46b9-9475-89b109d7c40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
